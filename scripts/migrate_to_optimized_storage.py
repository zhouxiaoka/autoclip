#!/usr/bin/env python3
"""
æ•°æ®å­˜å‚¨ä¼˜åŒ–è¿ç§»è„šæœ¬
å°†åŒé‡å­˜å‚¨æ¨¡å¼è¿ç§»åˆ°ä¼˜åŒ–å­˜å‚¨æ¨¡å¼ï¼ˆæ•°æ®åº“å­˜å‚¨å…ƒæ•°æ®ï¼Œæ–‡ä»¶ç³»ç»Ÿå­˜å‚¨å®é™…æ–‡ä»¶ï¼‰
"""

import sys
import os
import json
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.core.database import SessionLocal
from backend.services.optimized_storage_service import OptimizedStorageService
from backend.models.project import Project
from backend.models.clip import Clip
from backend.models.collection import Collection

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def analyze_current_storage():
    """åˆ†æå½“å‰å­˜å‚¨çŠ¶å†µ"""
    logger.info("ğŸ” åˆ†æå½“å‰å­˜å‚¨çŠ¶å†µ...")
    
    data_dir = project_root / "data"
    projects_dir = data_dir / "projects"
    
    if not projects_dir.exists():
        logger.warning("é¡¹ç›®ç›®å½•ä¸å­˜åœ¨")
        return {"projects": [], "total_size": 0}
    
    projects_info = []
    total_size = 0
    
    for project_dir in projects_dir.iterdir():
        if project_dir.is_dir() and not project_dir.name.startswith('.'):
            project_id = project_dir.name
            project_size = sum(f.stat().st_size for f in project_dir.rglob('*') if f.is_file())
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ•°æ®
            has_duplicate_data = False
            if (project_dir / "clips_metadata.json").exists():
                has_duplicate_data = True
            
            projects_info.append({
                "project_id": project_id,
                "size_mb": round(project_size / (1024 * 1024), 2),
                "has_duplicate_data": has_duplicate_data,
                "files_count": len(list(project_dir.rglob('*')))
            })
            
            total_size += project_size
    
    logger.info(f"ğŸ“Š åˆ†æå®Œæˆ: {len(projects_info)} ä¸ªé¡¹ç›®, æ€»å¤§å°: {round(total_size / (1024 * 1024), 2)} MB")
    
    return {
        "projects": projects_info,
        "total_size": total_size
    }


def migrate_project_to_optimized_storage(db, project_id: str, dry_run: bool = True):
    """è¿ç§»å•ä¸ªé¡¹ç›®åˆ°ä¼˜åŒ–å­˜å‚¨æ¨¡å¼"""
    logger.info(f"ğŸ”„ è¿ç§»é¡¹ç›®: {project_id} (dry_run={dry_run})")
    
    try:
        # è·å–é¡¹ç›®ä¿¡æ¯
        project = db.query(Project).filter(Project.id == project_id).first()
        if not project:
            logger.warning(f"é¡¹ç›® {project_id} åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨")
            return {"success": False, "error": "é¡¹ç›®ä¸å­˜åœ¨"}
        
        # æ£€æŸ¥é¡¹ç›®ç›®å½•
        data_dir = project_root / "data"
        old_project_dir = data_dir / "projects" / project_id
        
        if not old_project_dir.exists():
            logger.warning(f"é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {old_project_dir}")
            return {"success": False, "error": "é¡¹ç›®ç›®å½•ä¸å­˜åœ¨"}
        
        if dry_run:
            logger.info(f"ğŸ” æ¨¡æ‹Ÿè¿ç§»é¡¹ç›® {project_id}")
            return {"success": True, "dry_run": True, "message": "æ¨¡æ‹Ÿè¿ç§»æˆåŠŸ"}
        
        # åˆ›å»ºä¼˜åŒ–å­˜å‚¨æœåŠ¡
        storage_service = OptimizedStorageService(db, project_id)
        
        # æ‰§è¡Œè¿ç§»
        migration_result = storage_service.migrate_from_old_storage(old_project_dir)
        
        if migration_result["success"]:
            logger.info(f"âœ… é¡¹ç›® {project_id} è¿ç§»æˆåŠŸ")
            
            # æ¸…ç†æ—§çš„åŒé‡å­˜å‚¨æ–‡ä»¶
            cleanup_old_duplicate_files(old_project_dir)
            
            return {
                "success": True,
                "migrated_files": migration_result["migrated_files"],
                "migrated_metadata": migration_result["migrated_metadata"]
            }
        else:
            logger.error(f"âŒ é¡¹ç›® {project_id} è¿ç§»å¤±è´¥: {migration_result['error']}")
            return migration_result
            
    except Exception as e:
        logger.error(f"âŒ è¿ç§»é¡¹ç›® {project_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {"success": False, "error": str(e)}


def cleanup_old_duplicate_files(project_dir: Path):
    """æ¸…ç†æ—§çš„åŒé‡å­˜å‚¨æ–‡ä»¶"""
    try:
        logger.info(f"ğŸ§¹ æ¸…ç†é¡¹ç›® {project_dir.name} çš„é‡å¤æ–‡ä»¶...")
        
        # åˆ é™¤é‡å¤çš„å…ƒæ•°æ®æ–‡ä»¶
        duplicate_files = [
            "clips_metadata.json",
            "collections_metadata.json",
            "step1_outline.json",
            "step2_timeline.json",
            "step3_scoring.json",
            "step4_titles.json",
            "step5_collections.json"
        ]
        
        cleaned_count = 0
        for file_name in duplicate_files:
            file_path = project_dir / file_name
            if file_path.exists():
                # å¤‡ä»½æ–‡ä»¶
                backup_path = project_dir / f"{file_name}.backup"
                file_path.rename(backup_path)
                cleaned_count += 1
                logger.info(f"ğŸ“¦ å¤‡ä»½é‡å¤æ–‡ä»¶: {file_name}")
        
        logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œå¤‡ä»½äº† {cleaned_count} ä¸ªé‡å¤æ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†é‡å¤æ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ•°æ®å­˜å‚¨ä¼˜åŒ–è¿ç§»...")
    
    # åˆ†æå½“å‰å­˜å‚¨çŠ¶å†µ
    storage_info = analyze_current_storage()
    
    if not storage_info["projects"]:
        logger.info("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„é¡¹ç›®")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print("\nğŸ“Š å½“å‰å­˜å‚¨çŠ¶å†µåˆ†æ:")
    print("=" * 60)
    for project in storage_info["projects"]:
        status = "âš ï¸  æœ‰é‡å¤æ•°æ®" if project["has_duplicate_data"] else "âœ… æ­£å¸¸"
        print(f"é¡¹ç›® {project['project_id'][:8]}... | {project['size_mb']:>8.2f} MB | {project['files_count']:>4} æ–‡ä»¶ | {status}")
    
    print(f"\næ€»å¤§å°: {round(storage_info['total_size'] / (1024 * 1024), 2)} MB")
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    print("\n" + "=" * 60)
    print("ğŸ”§ è¿ç§»é€‰é¡¹:")
    print("1. æ¨¡æ‹Ÿè¿ç§» (dry run) - æŸ¥çœ‹è¿ç§»æ•ˆæœä½†ä¸å®é™…æ‰§è¡Œ")
    print("2. æ‰§è¡Œè¿ç§» - å®é™…è¿ç§»æ•°æ®å¹¶æ¸…ç†é‡å¤æ–‡ä»¶")
    print("3. é€€å‡º")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1/2/3): ").strip()
        if choice in ['1', '2', '3']:
            break
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
    
    if choice == '3':
        logger.info("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆè¿ç§»")
        return
    
    dry_run = (choice == '1')
    
    if dry_run:
        logger.info("ğŸ” å¼€å§‹æ¨¡æ‹Ÿè¿ç§»...")
    else:
        logger.info("ğŸš€ å¼€å§‹å®é™…è¿ç§»...")
        # åˆ›å»ºå¤‡ä»½
        backup_dir = project_root / f"migration_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_dir.mkdir(exist_ok=True)
        logger.info(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½ç›®å½•: {backup_dir}")
    
    # æ‰§è¡Œè¿ç§»
    db = SessionLocal()
    try:
        success_count = 0
        failed_count = 0
        
        for project_info in storage_info["projects"]:
            project_id = project_info["project_id"]
            
            result = migrate_project_to_optimized_storage(db, project_id, dry_run)
            
            if result["success"]:
                success_count += 1
                if dry_run:
                    logger.info(f"âœ… æ¨¡æ‹Ÿè¿ç§»æˆåŠŸ: {project_id}")
                else:
                    logger.info(f"âœ… è¿ç§»æˆåŠŸ: {project_id}")
            else:
                failed_count += 1
                logger.error(f"âŒ è¿ç§»å¤±è´¥: {project_id} - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æ˜¾ç¤ºè¿ç§»ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š è¿ç§»ç»“æœ:")
        print(f"âœ… æˆåŠŸ: {success_count}")
        print(f"âŒ å¤±è´¥: {failed_count}")
        print(f"ğŸ“Š æ€»è®¡: {success_count + failed_count}")
        
        if not dry_run and success_count > 0:
            print(f"\nğŸ’¾ å¤‡ä»½ä½ç½®: {backup_dir}")
            print("ğŸ”§ å»ºè®®:")
            print("1. æµ‹è¯•ç³»ç»ŸåŠŸèƒ½æ˜¯å¦æ­£å¸¸")
            print("2. ç¡®è®¤æ— è¯¯åå¯ä»¥åˆ é™¤å¤‡ä»½æ–‡ä»¶")
            print("3. è¿è¡Œæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        db.close()
    
    logger.info("ğŸ‰ è¿ç§»å®Œæˆ!")


if __name__ == "__main__":
    main()
