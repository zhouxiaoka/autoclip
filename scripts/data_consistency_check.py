#!/usr/bin/env python3
"""
æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œæ¸…ç†è„šæœ¬
æ£€æŸ¥å¹¶ä¿®å¤æ•°æ®åº“ä¸æ–‡ä»¶ç³»ç»Ÿä¹‹é—´çš„ä¸ä¸€è‡´é—®é¢˜
"""

import sys
import os
import json
import logging
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Set

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import sqlite3
from backend.core.database import SessionLocal
from backend.models.project import Project
from backend.models.task import Task, TaskStatus
from backend.models.clip import Clip
from backend.models.collection import Collection

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataConsistencyChecker:
    """æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, db_path: str = None):
        self.db_path = db_path or str(project_root / "data" / "autoclip.db")
        self.data_dir = project_root / "data"
        self.projects_dir = self.data_dir / "projects"
        
    def check_consistency(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        logger.info("ğŸ” å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
        
        issues = []
        warnings = []
        
        # 1. æ£€æŸ¥é¡¹ç›®æ•°æ®ä¸€è‡´æ€§
        project_issues = self._check_project_consistency()
        issues.extend(project_issues)
        
        # 2. æ£€æŸ¥ä»»åŠ¡æ•°æ®ä¸€è‡´æ€§
        task_issues = self._check_task_consistency()
        issues.extend(task_issues)
        
        # 3. æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸€è‡´æ€§
        file_issues = self._check_filesystem_consistency()
        issues.extend(file_issues)
        
        # 4. æ£€æŸ¥å­¤ç«‹æ•°æ®
        orphaned_data = self._check_orphaned_data()
        warnings.extend(orphaned_data)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "total_issues": len(issues),
            "total_warnings": len(warnings),
            "issues": issues,
            "warnings": warnings,
            "status": "healthy" if len(issues) == 0 else "unhealthy"
        }
    
    def _check_project_consistency(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥é¡¹ç›®æ•°æ®ä¸€è‡´æ€§"""
        issues = []
        
        try:
            # è·å–æ•°æ®åº“ä¸­çš„é¡¹ç›®
            db = SessionLocal()
            try:
                db_projects = db.query(Project).all()
                db_project_ids = {p.id for p in db_projects}
                
                # è·å–æ–‡ä»¶ç³»ç»Ÿä¸­çš„é¡¹ç›®ç›®å½•
                fs_project_ids = set()
                if self.projects_dir.exists():
                    for project_dir in self.projects_dir.iterdir():
                        if project_dir.is_dir() and not project_dir.name.startswith('.'):
                            fs_project_ids.add(project_dir.name)
                
                # æ£€æŸ¥å­¤ç«‹æ–‡ä»¶
                orphaned_files = fs_project_ids - db_project_ids
                if orphaned_files:
                    issues.append({
                        "type": "orphaned_files",
                        "severity": "warning",
                        "message": f"å‘ç° {len(orphaned_files)} ä¸ªå­¤ç«‹é¡¹ç›®æ–‡ä»¶",
                        "details": list(orphaned_files)
                    })
                
                # æ£€æŸ¥ç¼ºå¤±æ–‡ä»¶
                missing_files = db_project_ids - fs_project_ids
                if missing_files:
                    issues.append({
                        "type": "missing_files",
                        "severity": "error",
                        "message": f"å‘ç° {len(missing_files)} ä¸ªé¡¹ç›®çš„æ–‡ä»¶ç¼ºå¤±",
                        "details": list(missing_files)
                    })
                
                # æ£€æŸ¥å¼‚å¸¸é¡¹ç›®ç›®å½•
                if (self.projects_dir / "None").exists():
                    issues.append({
                        "type": "invalid_directory",
                        "severity": "warning",
                        "message": "å‘ç°æ— æ•ˆçš„é¡¹ç›®ç›®å½• 'None'",
                        "details": ["None"]
                    })
                
            finally:
                db.close()
                
        except Exception as e:
            issues.append({
                "type": "check_error",
                "severity": "error",
                "message": f"æ£€æŸ¥é¡¹ç›®ä¸€è‡´æ€§æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "details": []
            })
        
        return issues
    
    def _check_task_consistency(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ä»»åŠ¡æ•°æ®ä¸€è‡´æ€§"""
        issues = []
        
        try:
            db = SessionLocal()
            try:
                # æ£€æŸ¥é•¿æ—¶é—´è¿è¡Œçš„å¼‚å¸¸ä»»åŠ¡
                from datetime import timedelta
                cutoff_time = datetime.utcnow() - timedelta(hours=24)
                
                long_running_tasks = db.query(Task).filter(
                    Task.status == TaskStatus.RUNNING,
                    Task.created_at < cutoff_time
                ).all()
                
                if long_running_tasks:
                    issues.append({
                        "type": "long_running_tasks",
                        "severity": "warning",
                        "message": f"å‘ç° {len(long_running_tasks)} ä¸ªé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡",
                        "details": [{"id": t.id, "name": t.name, "created_at": t.created_at.isoformat()} for t in long_running_tasks]
                    })
                
                # æ£€æŸ¥å­¤ç«‹ä»»åŠ¡
                all_tasks = db.query(Task).all()
                all_project_ids = {p.id for p in db.query(Project).all()}
                
                orphaned_tasks = []
                for task in all_tasks:
                    if task.project_id not in all_project_ids:
                        orphaned_tasks.append(task)
                
                if orphaned_tasks:
                    issues.append({
                        "type": "orphaned_tasks",
                        "severity": "error",
                        "message": f"å‘ç° {len(orphaned_tasks)} ä¸ªå­¤ç«‹ä»»åŠ¡",
                        "details": [{"id": t.id, "name": t.name, "project_id": t.project_id} for t in orphaned_tasks]
                    })
                
            finally:
                db.close()
                
        except Exception as e:
            issues.append({
                "type": "check_error",
                "severity": "error",
                "message": f"æ£€æŸ¥ä»»åŠ¡ä¸€è‡´æ€§æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "details": []
            })
        
        return issues
    
    def _check_filesystem_consistency(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸€è‡´æ€§"""
        issues = []
        
        try:
            # æ£€æŸ¥é¡¹ç›®ç›®å½•ç»“æ„
            if self.projects_dir.exists():
                for project_dir in self.projects_dir.iterdir():
                    if project_dir.is_dir() and not project_dir.name.startswith('.'):
                        # æ£€æŸ¥å¿…è¦çš„ç›®å½•ç»“æ„
                        required_dirs = ["raw", "processing", "output"]
                        missing_dirs = []
                        
                        for req_dir in required_dirs:
                            if not (project_dir / req_dir).exists():
                                missing_dirs.append(req_dir)
                        
                        if missing_dirs:
                            issues.append({
                                "type": "missing_directories",
                                "severity": "warning",
                                "message": f"é¡¹ç›® {project_dir.name} ç¼ºå°‘ç›®å½•: {', '.join(missing_dirs)}",
                                "details": {"project_id": project_dir.name, "missing_dirs": missing_dirs}
                            })
                        
                        # æ£€æŸ¥é‡å¤çš„å…ƒæ•°æ®æ–‡ä»¶
                        metadata_files = [
                            "clips_metadata.json",
                            "collections_metadata.json",
                            "step1_outline.json",
                            "step2_timeline.json",
                            "step3_scoring.json",
                            "step4_titles.json",
                            "step5_collections.json"
                        ]
                        
                        duplicate_files = []
                        for metadata_file in metadata_files:
                            if (project_dir / metadata_file).exists():
                                duplicate_files.append(metadata_file)
                        
                        if duplicate_files:
                            issues.append({
                                "type": "duplicate_metadata",
                                "severity": "info",
                                "message": f"é¡¹ç›® {project_dir.name} å­˜åœ¨é‡å¤å…ƒæ•°æ®æ–‡ä»¶",
                                "details": {"project_id": project_dir.name, "duplicate_files": duplicate_files}
                            })
                
        except Exception as e:
            issues.append({
                "type": "check_error",
                "severity": "error",
                "message": f"æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸€è‡´æ€§æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "details": []
            })
        
        return issues
    
    def _check_orphaned_data(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å­¤ç«‹æ•°æ®"""
        warnings = []
        
        try:
            db = SessionLocal()
            try:
                # æ£€æŸ¥å­¤ç«‹çš„åˆ‡ç‰‡æ•°æ®
                all_clips = db.query(Clip).all()
                all_project_ids = {p.id for p in db.query(Project).all()}
                
                orphaned_clips = [clip for clip in all_clips if clip.project_id not in all_project_ids]
                if orphaned_clips:
                    warnings.append({
                        "type": "orphaned_clips",
                        "message": f"å‘ç° {len(orphaned_clips)} ä¸ªå­¤ç«‹åˆ‡ç‰‡",
                        "count": len(orphaned_clips)
                    })
                
                # æ£€æŸ¥å­¤ç«‹çš„åˆé›†æ•°æ®
                all_collections = db.query(Collection).all()
                orphaned_collections = [col for col in all_collections if col.project_id not in all_project_ids]
                if orphaned_collections:
                    warnings.append({
                        "type": "orphaned_collections",
                        "message": f"å‘ç° {len(orphaned_collections)} ä¸ªå­¤ç«‹åˆé›†",
                        "count": len(orphaned_collections)
                    })
                
            finally:
                db.close()
                
        except Exception as e:
            warnings.append({
                "type": "check_error",
                "message": f"æ£€æŸ¥å­¤ç«‹æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            })
        
        return warnings
    
    def fix_issues(self, issues: List[Dict[str, Any]], dry_run: bool = True) -> Dict[str, Any]:
        """ä¿®å¤å‘ç°çš„é—®é¢˜"""
        logger.info(f"ğŸ”§ å¼€å§‹ä¿®å¤é—®é¢˜ (dry_run={dry_run})")
        
        fixed_count = 0
        failed_count = 0
        fix_results = []
        
        for issue in issues:
            try:
                if issue["type"] == "orphaned_files":
                    result = self._fix_orphaned_files(issue["details"], dry_run)
                    fix_results.append(result)
                    if result["success"]:
                        fixed_count += 1
                    else:
                        failed_count += 1
                
                elif issue["type"] == "long_running_tasks":
                    result = self._fix_long_running_tasks(issue["details"], dry_run)
                    fix_results.append(result)
                    if result["success"]:
                        fixed_count += 1
                    else:
                        failed_count += 1
                
                elif issue["type"] == "invalid_directory":
                    result = self._fix_invalid_directory(issue["details"], dry_run)
                    fix_results.append(result)
                    if result["success"]:
                        fixed_count += 1
                    else:
                        failed_count += 1
                
                else:
                    logger.warning(f"æœªçŸ¥é—®é¢˜ç±»å‹: {issue['type']}")
                    
            except Exception as e:
                logger.error(f"ä¿®å¤é—®é¢˜å¤±è´¥: {issue['type']}, é”™è¯¯: {e}")
                failed_count += 1
        
        return {
            "fixed_count": fixed_count,
            "failed_count": failed_count,
            "fix_results": fix_results,
            "dry_run": dry_run
        }
    
    def _fix_orphaned_files(self, orphaned_files: List[str], dry_run: bool) -> Dict[str, Any]:
        """ä¿®å¤å­¤ç«‹æ–‡ä»¶"""
        try:
            if dry_run:
                logger.info(f"ğŸ” æ¨¡æ‹Ÿæ¸…ç†å­¤ç«‹æ–‡ä»¶: {orphaned_files}")
                return {"success": True, "action": "dry_run", "files": orphaned_files}
            
            cleaned_count = 0
            for project_id in orphaned_files:
                project_dir = self.projects_dir / project_id
                if project_dir.exists():
                    shutil.rmtree(project_dir)
                    cleaned_count += 1
                    logger.info(f"âœ… æ¸…ç†å­¤ç«‹é¡¹ç›®ç›®å½•: {project_id}")
            
            return {"success": True, "action": "cleanup", "cleaned_count": cleaned_count}
            
        except Exception as e:
            logger.error(f"æ¸…ç†å­¤ç«‹æ–‡ä»¶å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _fix_long_running_tasks(self, long_running_tasks: List[Dict], dry_run: bool) -> Dict[str, Any]:
        """ä¿®å¤é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡"""
        try:
            if dry_run:
                logger.info(f"ğŸ” æ¨¡æ‹Ÿä¿®å¤é•¿æ—¶é—´è¿è¡Œä»»åŠ¡: {len(long_running_tasks)} ä¸ª")
                return {"success": True, "action": "dry_run", "tasks": long_running_tasks}
            
            db = SessionLocal()
            try:
                fixed_count = 0
                for task_info in long_running_tasks:
                    task_id = task_info["id"]
                    task = db.query(Task).filter(Task.id == task_id).first()
                    if task:
                        task.status = TaskStatus.FAILED
                        task.error_message = "ä»»åŠ¡è¶…æ—¶ï¼Œå·²è‡ªåŠ¨æ ‡è®°ä¸ºå¤±è´¥"
                        task.updated_at = datetime.utcnow()
                        fixed_count += 1
                        logger.info(f"âœ… ä¿®å¤é•¿æ—¶é—´è¿è¡Œä»»åŠ¡: {task_id}")
                
                db.commit()
                return {"success": True, "action": "fix", "fixed_count": fixed_count}
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"ä¿®å¤é•¿æ—¶é—´è¿è¡Œä»»åŠ¡å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _fix_invalid_directory(self, invalid_dirs: List[str], dry_run: bool) -> Dict[str, Any]:
        """ä¿®å¤æ— æ•ˆç›®å½•"""
        try:
            if dry_run:
                logger.info(f"ğŸ” æ¨¡æ‹Ÿæ¸…ç†æ— æ•ˆç›®å½•: {invalid_dirs}")
                return {"success": True, "action": "dry_run", "dirs": invalid_dirs}
            
            cleaned_count = 0
            for dir_name in invalid_dirs:
                invalid_dir = self.projects_dir / dir_name
                if invalid_dir.exists():
                    shutil.rmtree(invalid_dir)
                    cleaned_count += 1
                    logger.info(f"âœ… æ¸…ç†æ— æ•ˆç›®å½•: {dir_name}")
            
            return {"success": True, "action": "cleanup", "cleaned_count": cleaned_count}
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ— æ•ˆç›®å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œä¿®å¤...")
    
    checker = DataConsistencyChecker()
    
    # 1. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
    result = checker.check_consistency()
    
    print("\n" + "=" * 80)
    print("ğŸ“Š æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ")
    print("=" * 80)
    print(f"æ£€æŸ¥æ—¶é—´: {result['timestamp']}")
    print(f"æ€»é—®é¢˜æ•°: {result['total_issues']}")
    print(f"æ€»è­¦å‘Šæ•°: {result['total_warnings']}")
    print(f"çŠ¶æ€: {result['status']}")
    
    if result['issues']:
        print("\nğŸš¨ å‘ç°çš„é—®é¢˜:")
        for i, issue in enumerate(result['issues'], 1):
            print(f"{i}. [{issue['severity'].upper()}] {issue['message']}")
            if issue.get('details'):
                print(f"   è¯¦æƒ…: {issue['details']}")
    
    if result['warnings']:
        print("\nâš ï¸  è­¦å‘Š:")
        for i, warning in enumerate(result['warnings'], 1):
            print(f"{i}. {warning['message']}")
    
    # 2. å¦‚æœæœ‰é—®é¢˜ï¼Œè¯¢é—®æ˜¯å¦ä¿®å¤
    if result['total_issues'] > 0:
        print("\n" + "=" * 60)
        print("ğŸ”§ ä¿®å¤é€‰é¡¹:")
        print("1. æ¨¡æ‹Ÿä¿®å¤ (dry run) - æŸ¥çœ‹ä¿®å¤æ•ˆæœä½†ä¸å®é™…æ‰§è¡Œ")
        print("2. æ‰§è¡Œä¿®å¤ - å®é™…ä¿®å¤å‘ç°çš„é—®é¢˜")
        print("3. é€€å‡º")
        
        while True:
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1/2/3): ").strip()
            if choice in ['1', '2', '3']:
                break
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
        
        if choice == '3':
            logger.info("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆä¿®å¤")
            return
        
        dry_run = (choice == '1')
        
        # æ‰§è¡Œä¿®å¤
        fix_result = checker.fix_issues(result['issues'], dry_run)
        
        print("\n" + "=" * 60)
        if dry_run:
            print("ğŸ” æ¨¡æ‹Ÿä¿®å¤ç»“æœ:")
        else:
            print("âœ… ä¿®å¤å®Œæˆ:")
        
        print(f"ä¿®å¤æˆåŠŸ: {fix_result['fixed_count']}")
        print(f"ä¿®å¤å¤±è´¥: {fix_result['failed_count']}")
        
        if fix_result['fix_results']:
            print("\nğŸ“‹ ä¿®å¤è¯¦æƒ…:")
            for i, fix_result_item in enumerate(fix_result['fix_results'], 1):
                status = "âœ…" if fix_result_item['success'] else "âŒ"
                print(f"{i}. {status} {fix_result_item.get('action', 'unknown')}")
                if not fix_result_item['success']:
                    print(f"   é”™è¯¯: {fix_result_item.get('error', 'unknown')}")
    
    else:
        print("\nğŸ‰ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ï¼Œæ— éœ€ä¿®å¤ï¼")
    
    logger.info("ğŸ‰ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œä¿®å¤å®Œæˆ!")


if __name__ == "__main__":
    main()
