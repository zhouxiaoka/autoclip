#!/usr/bin/env python3
"""
é…ç½®è¿ç§»è„šæœ¬
å°†æ—§çš„åˆ†æ•£é…ç½®ç³»ç»Ÿè¿ç§»åˆ°æ–°çš„ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
"""

import sys
import os
import json
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.core.unified_config import UnifiedConfig, config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def analyze_old_configs():
    """åˆ†ææ—§çš„é…ç½®æ–‡ä»¶"""
    logger.info("ğŸ” åˆ†ææ—§é…ç½®æ–‡ä»¶...")
    
    old_configs = {}
    
    # æ£€æŸ¥data/settings.json
    settings_file = project_root / "data" / "settings.json"
    if settings_file.exists():
        try:
            with open(settings_file, 'r', encoding='utf-8') as f:
                old_configs['settings.json'] = json.load(f)
            logger.info(f"âœ… æ‰¾åˆ°é…ç½®æ–‡ä»¶: {settings_file}")
        except Exception as e:
            logger.warning(f"âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    # æ£€æŸ¥.envæ–‡ä»¶
    env_file = project_root / ".env"
    if env_file.exists():
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                env_content = f.read()
                old_configs['.env'] = parse_env_file(env_content)
            logger.info(f"âœ… æ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
        except Exception as e:
            logger.warning(f"âš ï¸  è¯»å–ç¯å¢ƒå˜é‡æ–‡ä»¶å¤±è´¥: {e}")
    
    # æ£€æŸ¥backend/core/config.pyä¸­çš„é»˜è®¤å€¼
    old_configs['config.py_defaults'] = {
        "database_url": "sqlite:///./data/autoclip.db",
        "redis_url": "redis://localhost:6379/0",
        "api_dashscope_api_key": "",
        "api_model_name": "qwen-plus",
        "processing_chunk_size": 5000,
        "processing_min_score_threshold": 0.7,
        "log_level": "INFO"
    }
    
    return old_configs


def parse_env_file(env_content: str) -> dict:
    """è§£æ.envæ–‡ä»¶å†…å®¹"""
    env_vars = {}
    for line in env_content.split('\n'):
        line = line.strip()
        if line and not line.startswith('#') and '=' in line:
            key, value = line.split('=', 1)
            env_vars[key.strip()] = value.strip().strip('"\'')
    return env_vars


def migrate_configs(old_configs: dict, dry_run: bool = True):
    """è¿ç§»é…ç½®åˆ°æ–°çš„ç»Ÿä¸€é…ç½®ç³»ç»Ÿ"""
    logger.info(f"ğŸ”„ å¼€å§‹é…ç½®è¿ç§» (dry_run={dry_run})")
    
    migration_log = {
        "timestamp": datetime.now().isoformat(),
        "dry_run": dry_run,
        "migrated_settings": {},
        "issues": []
    }
    
    try:
        # åˆ›å»ºæ–°çš„é…ç½®å®ä¾‹
        new_config = UnifiedConfig()
        
        # è¿ç§»settings.jsonä¸­çš„é…ç½®
        if 'settings.json' in old_configs:
            settings = old_configs['settings.json']
            migrated_settings = migrate_settings_json(settings, new_config)
            migration_log['migrated_settings']['settings.json'] = migrated_settings
        
        # è¿ç§».envæ–‡ä»¶ä¸­çš„é…ç½®
        if '.env' in old_configs:
            env_vars = old_configs['.env']
            migrated_env = migrate_env_vars(env_vars, new_config)
            migration_log['migrated_settings']['.env'] = migrated_env
        
        # éªŒè¯æ–°é…ç½®
        validation_result = new_config.validate_config()
        if not validation_result['valid']:
            migration_log['issues'].extend(validation_result['issues'])
        
        if dry_run:
            logger.info("ğŸ” æ¨¡æ‹Ÿè¿ç§»å®Œæˆ")
            return {
                "success": True,
                "dry_run": True,
                "migration_log": migration_log,
                "new_config_summary": new_config.get_config_summary()
            }
        
        # å®é™…è¿ç§»
        if not migration_log['issues']:
            # å¤‡ä»½æ—§é…ç½®
            backup_old_configs(old_configs)
            
            # ä¿å­˜æ–°é…ç½®
            new_config.save_to_file()
            
            logger.info("âœ… é…ç½®è¿ç§»å®Œæˆ")
            return {
                "success": True,
                "migration_log": migration_log,
                "new_config_summary": new_config.get_config_summary()
            }
        else:
            logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œæ— æ³•è¿ç§»")
            return {
                "success": False,
                "migration_log": migration_log
            }
            
    except Exception as e:
        logger.error(f"âŒ é…ç½®è¿ç§»å¤±è´¥: {e}")
        migration_log['issues'].append(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {
            "success": False,
            "migration_log": migration_log
        }


def migrate_settings_json(settings: dict, new_config: UnifiedConfig) -> dict:
    """è¿ç§»settings.jsonä¸­çš„é…ç½®"""
    migrated = {}
    
    # APIé…ç½®
    if 'dashscope_api_key' in settings:
        new_config.api.dashscope_api_key = settings['dashscope_api_key']
        migrated['dashscope_api_key'] = 'migrated'
    
    if 'model_name' in settings:
        new_config.api.model_name = settings['model_name']
        migrated['model_name'] = 'migrated'
    
    # å¤„ç†é…ç½®
    if 'chunk_size' in settings:
        new_config.processing.chunk_size = settings['chunk_size']
        migrated['chunk_size'] = 'migrated'
    
    if 'min_score_threshold' in settings:
        new_config.processing.min_score_threshold = settings['min_score_threshold']
        migrated['min_score_threshold'] = 'migrated'
    
    if 'max_clips_per_collection' in settings:
        new_config.processing.max_clips_per_collection = settings['max_clips_per_collection']
        migrated['max_clips_per_collection'] = 'migrated'
    
    # è¯­éŸ³è¯†åˆ«é…ç½®
    if 'speech_recognition_method' in settings:
        new_config.speech_recognition.method = settings['speech_recognition_method']
        migrated['speech_recognition_method'] = 'migrated'
    
    if 'speech_recognition_language' in settings:
        new_config.speech_recognition.language = settings['speech_recognition_language']
        migrated['speech_recognition_language'] = 'migrated'
    
    # Bç«™é…ç½®
    if 'bilibili_auto_upload' in settings:
        new_config.bilibili.auto_upload = settings['bilibili_auto_upload']
        migrated['bilibili_auto_upload'] = 'migrated'
    
    if 'bilibili_default_tid' in settings:
        new_config.bilibili.default_tid = settings['bilibili_default_tid']
        migrated['bilibili_default_tid'] = 'migrated'
    
    return migrated


def migrate_env_vars(env_vars: dict, new_config: UnifiedConfig) -> dict:
    """è¿ç§»ç¯å¢ƒå˜é‡"""
    migrated = {}
    
    # æ•°æ®åº“é…ç½®
    if 'DATABASE_URL' in env_vars:
        new_config.database.url = env_vars['DATABASE_URL']
        migrated['DATABASE_URL'] = 'migrated'
    
    # Redisé…ç½®
    if 'REDIS_URL' in env_vars:
        new_config.redis.url = env_vars['REDIS_URL']
        migrated['REDIS_URL'] = 'migrated'
    
    # APIé…ç½®
    if 'DASHSCOPE_API_KEY' in env_vars:
        new_config.api.dashscope_api_key = env_vars['DASHSCOPE_API_KEY']
        migrated['DASHSCOPE_API_KEY'] = 'migrated'
    
    if 'API_MODEL_NAME' in env_vars:
        new_config.api.model_name = env_vars['API_MODEL_NAME']
        migrated['API_MODEL_NAME'] = 'migrated'
    
    # å¤„ç†é…ç½®
    if 'PROCESSING_CHUNK_SIZE' in env_vars:
        new_config.processing.chunk_size = int(env_vars['PROCESSING_CHUNK_SIZE'])
        migrated['PROCESSING_CHUNK_SIZE'] = 'migrated'
    
    if 'PROCESSING_MIN_SCORE_THRESHOLD' in env_vars:
        new_config.processing.min_score_threshold = float(env_vars['PROCESSING_MIN_SCORE_THRESHOLD'])
        migrated['PROCESSING_MIN_SCORE_THRESHOLD'] = 'migrated'
    
    # æ—¥å¿—é…ç½®
    if 'LOG_LEVEL' in env_vars:
        new_config.logging.level = env_vars['LOG_LEVEL']
        migrated['LOG_LEVEL'] = 'migrated'
    
    if 'LOG_FILE' in env_vars:
        new_config.logging.file = env_vars['LOG_FILE']
        migrated['LOG_FILE'] = 'migrated'
    
    return migrated


def backup_old_configs(old_configs: dict):
    """å¤‡ä»½æ—§é…ç½®æ–‡ä»¶"""
    backup_dir = project_root / f"config_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    backup_dir.mkdir(exist_ok=True)
    
    logger.info(f"ğŸ“¦ åˆ›å»ºé…ç½®å¤‡ä»½: {backup_dir}")
    
    # å¤‡ä»½settings.json
    if 'settings.json' in old_configs:
        settings_file = project_root / "data" / "settings.json"
        if settings_file.exists():
            backup_file = backup_dir / "settings.json"
            with open(settings_file, 'r', encoding='utf-8') as src, \
                 open(backup_file, 'w', encoding='utf-8') as dst:
                dst.write(src.read())
    
    # å¤‡ä»½.envæ–‡ä»¶
    env_file = project_root / ".env"
    if env_file.exists():
        backup_file = backup_dir / ".env"
        with open(env_file, 'r', encoding='utf-8') as src, \
             open(backup_file, 'w', encoding='utf-8') as dst:
            dst.write(src.read())
    
    # ä¿å­˜è¿ç§»æ—¥å¿—
    migration_log_file = backup_dir / "migration_log.json"
    with open(migration_log_file, 'w', encoding='utf-8') as f:
        json.dump(old_configs, f, ensure_ascii=False, indent=2)
    
    logger.info(f"âœ… é…ç½®å¤‡ä»½å®Œæˆ: {backup_dir}")


def display_config_comparison(old_configs: dict, new_config_summary: dict):
    """æ˜¾ç¤ºé…ç½®å¯¹æ¯”"""
    print("\n" + "=" * 80)
    print("ğŸ“Š é…ç½®å¯¹æ¯”")
    print("=" * 80)
    
    print("\nğŸ”§ APIé…ç½®:")
    print(f"  æ¨¡å‹åç§°: {new_config_summary['api']['model_name']}")
    print(f"  æœ€å¤§Token: {new_config_summary['api']['max_tokens']}")
    print(f"  è¶…æ—¶æ—¶é—´: {new_config_summary['api']['timeout']}ç§’")
    print(f"  APIå¯†é’¥: {'å·²é…ç½®' if new_config_summary['api']['has_api_key'] else 'æœªé…ç½®'}")
    
    print("\nâš™ï¸  å¤„ç†é…ç½®:")
    print(f"  åˆ†å—å¤§å°: {new_config_summary['processing']['chunk_size']}")
    print(f"  æœ€å°è¯„åˆ†é˜ˆå€¼: {new_config_summary['processing']['min_score_threshold']}")
    print(f"  æœ€å¤§åˆ‡ç‰‡æ•°: {new_config_summary['processing']['max_clips_per_collection']}")
    
    print("\nğŸ—„ï¸  æ•°æ®åº“é…ç½®:")
    print(f"  æ•°æ®åº“URL: {new_config_summary['database']['url']}")
    print(f"  Redis URL: {new_config_summary['redis']['url']}")
    
    print("\nğŸ“ è·¯å¾„é…ç½®:")
    print(f"  æ•°æ®ç›®å½•: {new_config_summary['paths']['data_dir']}")
    print(f"  ä¸Šä¼ ç›®å½•: {new_config_summary['paths']['uploads_dir']}")
    print(f"  è¾“å‡ºç›®å½•: {new_config_summary['paths']['output_dir']}")
    
    print("\nğŸ“ æ—¥å¿—é…ç½®:")
    print(f"  æ—¥å¿—çº§åˆ«: {new_config_summary['logging']['level']}")
    print(f"  æ—¥å¿—æ–‡ä»¶: {new_config_summary['logging']['file']}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹é…ç½®è¿ç§»...")
    
    # åˆ†ææ—§é…ç½®
    old_configs = analyze_old_configs()
    
    if not old_configs:
        logger.info("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„é…ç½®æ–‡ä»¶")
        return
    
    print("\nğŸ“‹ å‘ç°çš„é…ç½®æ–‡ä»¶:")
    for config_name in old_configs.keys():
        print(f"  â€¢ {config_name}")
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    print("\n" + "=" * 60)
    print("ğŸ”§ è¿ç§»é€‰é¡¹:")
    print("1. æ¨¡æ‹Ÿè¿ç§» (dry run) - æŸ¥çœ‹è¿ç§»æ•ˆæœä½†ä¸å®é™…æ‰§è¡Œ")
    print("2. æ‰§è¡Œè¿ç§» - å®é™…è¿ç§»é…ç½®å¹¶å¤‡ä»½æ—§æ–‡ä»¶")
    print("3. é€€å‡º")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1/2/3): ").strip()
        if choice in ['1', '2', '3']:
            break
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
    
    if choice == '3':
        logger.info("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆè¿ç§»")
        return
    
    dry_run = (choice == '1')
    
    # æ‰§è¡Œè¿ç§»
    result = migrate_configs(old_configs, dry_run)
    
    if result['success']:
        if dry_run:
            print("\nğŸ” æ¨¡æ‹Ÿè¿ç§»ç»“æœ:")
        else:
            print("\nâœ… è¿ç§»å®Œæˆ:")
        
        # æ˜¾ç¤ºé…ç½®å¯¹æ¯”
        if 'new_config_summary' in result:
            display_config_comparison(old_configs, result['new_config_summary'])
        
        # æ˜¾ç¤ºè¿ç§»æ—¥å¿—
        migration_log = result['migration_log']
        if migration_log['migrated_settings']:
            print("\nğŸ“Š è¿ç§»ç»Ÿè®¡:")
            for config_name, migrated in migration_log['migrated_settings'].items():
                print(f"  {config_name}: {len(migrated)} ä¸ªè®¾ç½®é¡¹")
        
        # æ˜¾ç¤ºé—®é¢˜
        if migration_log['issues']:
            print("\nâš ï¸  å‘ç°çš„é—®é¢˜:")
            for issue in migration_log['issues']:
                print(f"  â€¢ {issue}")
        
        if not dry_run:
            print(f"\nğŸ’¾ å¤‡ä»½ä½ç½®: config_backup_*")
            print("ğŸ”§ å»ºè®®:")
            print("1. æµ‹è¯•ç³»ç»ŸåŠŸèƒ½æ˜¯å¦æ­£å¸¸")
            print("2. ç¡®è®¤æ— è¯¯åå¯ä»¥åˆ é™¤å¤‡ä»½æ–‡ä»¶")
            print("3. æ£€æŸ¥æ–°çš„é…ç½®æ–‡ä»¶æ ¼å¼")
    
    else:
        print("\nâŒ è¿ç§»å¤±è´¥:")
        migration_log = result['migration_log']
        if migration_log['issues']:
            for issue in migration_log['issues']:
                print(f"  â€¢ {issue}")
    
    logger.info("ğŸ‰ é…ç½®è¿ç§»å®Œæˆ!")


if __name__ == "__main__":
    main()
