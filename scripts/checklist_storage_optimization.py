#!/usr/bin/env python3
"""
å­˜å‚¨ä¼˜åŒ–å®æ–½æ£€æŸ¥æ¸…å•
"""

import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
backend_dir = project_root / "backend"
sys.path.insert(0, str(backend_dir))

def check_database_models():
    """æ£€æŸ¥æ•°æ®åº“æ¨¡å‹ä¼˜åŒ–çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥æ•°æ®åº“æ¨¡å‹ä¼˜åŒ–çŠ¶æ€...")
    
    checklist = {
        "Clipæ¨¡å‹ä¼˜åŒ–": {
            "ç§»é™¤processing_resultå­—æ®µ": False,
            "ä¼˜åŒ–clip_metadataå­—æ®µ": False,
            "ä¿ç•™video_pathå­—æ®µ": False,
            "ä¿ç•™thumbnail_pathå­—æ®µ": False
        },
        "Projectæ¨¡å‹ä¼˜åŒ–": {
            "æ·»åŠ video_pathå­—æ®µ": False,
            "æ·»åŠ subtitle_pathå­—æ®µ": False,
            "ä¼˜åŒ–project_metadataå­—æ®µ": False
        },
        "Collectionæ¨¡å‹ä¼˜åŒ–": {
            "æ·»åŠ export_pathå­—æ®µ": False,
            "ä¼˜åŒ–collection_metadataå­—æ®µ": False
        }
    }
    
    # æ£€æŸ¥Clipæ¨¡å‹
    try:
        from models.clip import Clip
        clip_columns = [col.name for col in Clip.__table__.columns]
        
        if "processing_result" not in clip_columns:
            checklist["Clipæ¨¡å‹ä¼˜åŒ–"]["ç§»é™¤processing_resultå­—æ®µ"] = True
        
        if "video_path" in clip_columns:
            checklist["Clipæ¨¡å‹ä¼˜åŒ–"]["ä¿ç•™video_pathå­—æ®µ"] = True
            
        if "thumbnail_path" in clip_columns:
            checklist["Clipæ¨¡å‹ä¼˜åŒ–"]["ä¿ç•™thumbnail_pathå­—æ®µ"] = True
        
        # æ£€æŸ¥è®¡ç®—å±æ€§
        if hasattr(Clip, 'metadata_file_path'):
            checklist["Clipæ¨¡å‹ä¼˜åŒ–"]["ä¼˜åŒ–clip_metadataå­—æ®µ"] = True
            
    except ImportError:
        print("    âŒ æ— æ³•å¯¼å…¥Clipæ¨¡å‹")
    
    # æ£€æŸ¥Projectæ¨¡å‹
    try:
        from models.project import Project
        project_columns = [col.name for col in Project.__table__.columns]
        
        if "video_path" in project_columns:
            checklist["Projectæ¨¡å‹ä¼˜åŒ–"]["æ·»åŠ video_pathå­—æ®µ"] = True
            
        if "subtitle_path" in project_columns:
            checklist["Projectæ¨¡å‹ä¼˜åŒ–"]["æ·»åŠ subtitle_pathå­—æ®µ"] = True
        
        # æ£€æŸ¥è®¡ç®—å±æ€§
        if hasattr(Project, 'storage_initialized'):
            checklist["Projectæ¨¡å‹ä¼˜åŒ–"]["ä¼˜åŒ–project_metadataå­—æ®µ"] = True
            
    except ImportError:
        print("    âŒ æ— æ³•å¯¼å…¥Projectæ¨¡å‹")
    
    # æ£€æŸ¥Collectionæ¨¡å‹
    try:
        from models.collection import Collection
        collection_columns = [col.name for col in Collection.__table__.columns]
        
        if "export_path" in collection_columns:
            checklist["Collectionæ¨¡å‹ä¼˜åŒ–"]["æ·»åŠ export_pathå­—æ®µ"] = True
        
        # æ£€æŸ¥è®¡ç®—å±æ€§
        if hasattr(Collection, 'metadata_file_path'):
            checklist["Collectionæ¨¡å‹ä¼˜åŒ–"]["ä¼˜åŒ–collection_metadataå­—æ®µ"] = True
            
    except ImportError:
        print("    âŒ æ— æ³•å¯¼å…¥Collectionæ¨¡å‹")
    
    return checklist

def check_storage_service():
    """æ£€æŸ¥å­˜å‚¨æœåŠ¡çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥å­˜å‚¨æœåŠ¡çŠ¶æ€...")
    
    checklist = {
        "StorageService": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "save_metadataæ–¹æ³•": False,
            "save_fileæ–¹æ³•": False,
            "get_file_pathæ–¹æ³•": False,
            "cleanup_temp_filesæ–¹æ³•": False
        }
    }
    
    storage_service_path = backend_dir / "services" / "storage_service.py"
    
    if storage_service_path.exists():
        checklist["StorageService"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        # è¯»å–æ–‡ä»¶å†…å®¹æ£€æŸ¥æ–¹æ³•
        with open(storage_service_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "def save_metadata" in content:
            checklist["StorageService"]["save_metadataæ–¹æ³•"] = True
            
        if "def save_file" in content:
            checklist["StorageService"]["save_fileæ–¹æ³•"] = True
            
        if "def get_file_path" in content:
            checklist["StorageService"]["get_file_pathæ–¹æ³•"] = True
            
        if "def cleanup_temp_files" in content:
            checklist["StorageService"]["cleanup_temp_filesæ–¹æ³•"] = True
    
    return checklist

def check_pipeline_adapter():
    """æ£€æŸ¥PipelineAdapterä¼˜åŒ–çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥PipelineAdapterä¼˜åŒ–çŠ¶æ€...")
    
    checklist = {
        "PipelineAdapter": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "ä½¿ç”¨StorageService": False,
            "åˆ†ç¦»å­˜å‚¨é€»è¾‘": False
        }
    }
    
    pipeline_adapter_path = backend_dir / "services" / "pipeline_adapter.py"
    
    if pipeline_adapter_path.exists():
        checklist["PipelineAdapter"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        # è¯»å–æ–‡ä»¶å†…å®¹æ£€æŸ¥
        with open(pipeline_adapter_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "StorageService" in content:
            checklist["PipelineAdapter"]["ä½¿ç”¨StorageService"] = True
            
        if "_save_clips_to_database" in content and "_save_collections_to_database" in content:
            checklist["PipelineAdapter"]["åˆ†ç¦»å­˜å‚¨é€»è¾‘"] = True
    
    return checklist

def check_repositories():
    """æ£€æŸ¥Repositoryå±‚ä¼˜åŒ–çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥Repositoryå±‚ä¼˜åŒ–çŠ¶æ€...")
    
    checklist = {
        "ClipRepository": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "åˆ†ç¦»å­˜å‚¨æ–¹æ³•": False,
            "æ–‡ä»¶è®¿é—®æ–¹æ³•": False
        },
        "CollectionRepository": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "åˆ†ç¦»å­˜å‚¨æ–¹æ³•": False,
            "æ–‡ä»¶è®¿é—®æ–¹æ³•": False
        },
        "ProjectRepository": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "æ–‡ä»¶è·¯å¾„ç®¡ç†": False
        }
    }
    
    # æ£€æŸ¥ClipRepository
    clip_repo_path = backend_dir / "repositories" / "clip_repository.py"
    if clip_repo_path.exists():
        checklist["ClipRepository"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(clip_repo_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "get_clip_file" in content:
            checklist["ClipRepository"]["æ–‡ä»¶è®¿é—®æ–¹æ³•"] = True
        
        if "create_clip" in content:
            checklist["ClipRepository"]["åˆ†ç¦»å­˜å‚¨æ–¹æ³•"] = True
    
    # æ£€æŸ¥CollectionRepository
    collection_repo_path = backend_dir / "repositories" / "collection_repository.py"
    if collection_repo_path.exists():
        checklist["CollectionRepository"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(collection_repo_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "get_collection_file" in content:
            checklist["CollectionRepository"]["æ–‡ä»¶è®¿é—®æ–¹æ³•"] = True
        
        if "create_collection" in content:
            checklist["CollectionRepository"]["åˆ†ç¦»å­˜å‚¨æ–¹æ³•"] = True
    
    # æ£€æŸ¥ProjectRepository
    project_repo_path = backend_dir / "repositories" / "project_repository.py"
    if project_repo_path.exists():
        checklist["ProjectRepository"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(project_repo_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "get_project_file_paths" in content:
            checklist["ProjectRepository"]["æ–‡ä»¶è·¯å¾„ç®¡ç†"] = True
    
    return checklist

def check_api_endpoints():
    """æ£€æŸ¥APIç«¯ç‚¹ä¼˜åŒ–çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥APIç«¯ç‚¹ä¼˜åŒ–çŠ¶æ€...")
    
    checklist = {
        "æ–‡ä»¶ä¸Šä¼ API": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "ä¼˜åŒ–å­˜å‚¨é€»è¾‘": False
        },
        "åˆ‡ç‰‡API": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "æŒ‰éœ€åŠ è½½æ•°æ®": False
        },
        "åˆé›†API": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "æŒ‰éœ€åŠ è½½æ•°æ®": False
        },
        "æ–‡ä»¶è®¿é—®API": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "å†…å®¹è®¿é—®ç«¯ç‚¹": False
        }
    }
    
    # æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ API
    files_api_path = backend_dir / "api" / "v1" / "files.py"
    if files_api_path.exists():
        checklist["æ–‡ä»¶ä¸Šä¼ API"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(files_api_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "upload" in content:
            checklist["æ–‡ä»¶ä¸Šä¼ API"]["ä¼˜åŒ–å­˜å‚¨é€»è¾‘"] = True
    
    # æ£€æŸ¥åˆ‡ç‰‡API
    clips_api_path = backend_dir / "api" / "v1" / "clips.py"
    if clips_api_path.exists():
        checklist["åˆ‡ç‰‡API"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(clips_api_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "get_clips" in content:
            checklist["åˆ‡ç‰‡API"]["æŒ‰éœ€åŠ è½½æ•°æ®"] = True
    
    # æ£€æŸ¥åˆé›†API
    collections_api_path = backend_dir / "api" / "v1" / "collections.py"
    if collections_api_path.exists():
        checklist["åˆé›†API"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(collections_api_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "include_content" in content:
            checklist["åˆé›†API"]["æŒ‰éœ€åŠ è½½æ•°æ®"] = True
    
    # æ£€æŸ¥æ–‡ä»¶è®¿é—®API
    files_api_path = backend_dir / "api" / "v1" / "files.py"
    if files_api_path.exists():
        checklist["æ–‡ä»¶è®¿é—®API"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(files_api_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "get_clip_content" in content:
            checklist["æ–‡ä»¶è®¿é—®API"]["å†…å®¹è®¿é—®ç«¯ç‚¹"] = True
    
    return checklist

def check_migration_scripts():
    """æ£€æŸ¥æ•°æ®è¿ç§»è„šæœ¬çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥æ•°æ®è¿ç§»è„šæœ¬çŠ¶æ€...")
    
    checklist = {
        "è¿ç§»è„šæœ¬": {
            "æ–‡ä»¶å­˜åœ¨": False,
            "æ•°æ®éªŒè¯": False,
            "å›æ»šæœºåˆ¶": False
        }
    }
    
    migration_script_path = backend_dir / "migrations" / "optimize_storage_models.py"
    
    if migration_script_path.exists():
        checklist["è¿ç§»è„šæœ¬"]["æ–‡ä»¶å­˜åœ¨"] = True
        
        with open(migration_script_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if "validate_migration" in content:
            checklist["è¿ç§»è„šæœ¬"]["æ•°æ®éªŒè¯"] = True
            
        if "rollback_migration" in content:
            checklist["è¿ç§»è„šæœ¬"]["å›æ»šæœºåˆ¶"] = True
    
    return checklist

def check_file_structure():
    """æ£€æŸ¥æ–‡ä»¶ç»“æ„ä¼˜åŒ–çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥æ–‡ä»¶ç»“æ„ä¼˜åŒ–çŠ¶æ€...")
    
    checklist = {
        "ç›®å½•ç»“æ„": {
            "tempç›®å½•": False,
            "cacheç›®å½•": False,
            "backupsç›®å½•": False,
            "ç¤ºä¾‹é¡¹ç›®ç»“æ„": False
        }
    }
    
    data_dir = project_root / "data"
    
    if (data_dir / "temp").exists():
        checklist["ç›®å½•ç»“æ„"]["tempç›®å½•"] = True
        
    if (data_dir / "cache").exists():
        checklist["ç›®å½•ç»“æ„"]["cacheç›®å½•"] = True
        
    if (data_dir / "backups").exists():
        checklist["ç›®å½•ç»“æ„"]["backupsç›®å½•"] = True
        
    if (data_dir / "projects" / "example-project").exists():
        checklist["ç›®å½•ç»“æ„"]["ç¤ºä¾‹é¡¹ç›®ç»“æ„"] = True
    
    return checklist

def print_checklist_results(all_checklists: Dict[str, Dict[str, Dict[str, bool]]]):
    """æ‰“å°æ£€æŸ¥æ¸…å•ç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“‹ å­˜å‚¨ä¼˜åŒ–å®æ–½æ£€æŸ¥æ¸…å•ç»“æœ")
    print("="*60)
    
    total_items = 0
    completed_items = 0
    
    for category, items in all_checklists.items():
        print(f"\nğŸ”¸ {category}")
        print("-" * 40)
        
        for subcategory, checks in items.items():
            print(f"  ğŸ“ {subcategory}")
            
            for check_name, completed in checks.items():
                status = "âœ…" if completed else "âŒ"
                print(f"    {status} {check_name}")
                total_items += 1
                if completed:
                    completed_items += 1
    
    print("\n" + "="*60)
    completion_rate = (completed_items / total_items * 100) if total_items > 0 else 0
    print(f"ğŸ“Š æ€»ä½“å®Œæˆåº¦: {completion_rate:.1f}% ({completed_items}/{total_items})")
    
    if completion_rate >= 80:
        print("ğŸ‰ å­˜å‚¨ä¼˜åŒ–å®æ–½è¿›å±•è‰¯å¥½ï¼")
    elif completion_rate >= 50:
        print("ğŸš§ å­˜å‚¨ä¼˜åŒ–å®æ–½è¿›è¡Œä¸­ï¼Œéœ€è¦ç»§ç»­æ¨è¿›")
    else:
        print("âš ï¸ å­˜å‚¨ä¼˜åŒ–å®æ–½éœ€è¦åŠ å¿«è¿›åº¦")
    
    print("="*60)

def generate_next_steps(all_checklists: Dict[str, Dict[str, Dict[str, bool]]]):
    """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’"""
    print("\nğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’:")
    print("-" * 40)
    
    next_steps = []
    
    # æ£€æŸ¥æ•°æ®åº“æ¨¡å‹ä¼˜åŒ–
    db_models = all_checklists.get("æ•°æ®åº“æ¨¡å‹ä¼˜åŒ–", {})
    for subcategory, checks in db_models.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥å­˜å‚¨æœåŠ¡
    storage_service = all_checklists.get("å­˜å‚¨æœåŠ¡", {})
    for subcategory, checks in storage_service.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥PipelineAdapter
    pipeline_adapter = all_checklists.get("PipelineAdapter", {})
    for subcategory, checks in pipeline_adapter.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥Repositoryå±‚
    repositories = all_checklists.get("Repositoryå±‚", {})
    for subcategory, checks in repositories.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥APIç«¯ç‚¹
    api_endpoints = all_checklists.get("APIç«¯ç‚¹", {})
    for subcategory, checks in api_endpoints.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥è¿ç§»è„šæœ¬
    migration_scripts = all_checklists.get("è¿ç§»è„šæœ¬", {})
    for subcategory, checks in migration_scripts.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    # æ£€æŸ¥æ–‡ä»¶ç»“æ„
    file_structure = all_checklists.get("æ–‡ä»¶ç»“æ„", {})
    for subcategory, checks in file_structure.items():
        for check_name, completed in checks.items():
            if not completed:
                next_steps.append(f"ğŸ”§ å®Œæˆ {subcategory} - {check_name}")
    
    if next_steps:
        for i, step in enumerate(next_steps[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"{i}. {step}")
        
        if len(next_steps) > 10:
            print(f"... è¿˜æœ‰ {len(next_steps) - 10} ä¸ªä»»åŠ¡")
    else:
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å­˜å‚¨ä¼˜åŒ–å®æ–½æ£€æŸ¥...")
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    all_checklists = {
        "æ•°æ®åº“æ¨¡å‹ä¼˜åŒ–": check_database_models(),
        "å­˜å‚¨æœåŠ¡": check_storage_service(),
        "PipelineAdapter": check_pipeline_adapter(),
        "Repositoryå±‚": check_repositories(),
        "APIç«¯ç‚¹": check_api_endpoints(),
        "è¿ç§»è„šæœ¬": check_migration_scripts(),
        "æ–‡ä»¶ç»“æ„": check_file_structure()
    }
    
    # æ‰“å°ç»“æœ
    print_checklist_results(all_checklists)
    
    # ç”Ÿæˆä¸‹ä¸€æ­¥è®¡åˆ’
    generate_next_steps(all_checklists)
    
    print("\nğŸ“š ç›¸å…³æ–‡æ¡£:")
    print("- docs/STORAGE_ARCHITECTURE_OPTIMIZATION.md")
    print("- docs/STORAGE_OPTIMIZATION_WORK_BREAKDOWN.md")
    print("- docs/STORAGE_ARCHITECTURE_ANALYSIS.md")

if __name__ == "__main__":
    main()
