"""
è¯­éŸ³è¯†åˆ«å·¥å…· - æ”¯æŒå¤šç§è¯­éŸ³è¯†åˆ«æœåŠ¡
æ”¯æŒæœ¬åœ°Whisperã€OpenAI APIã€Azure Speech Servicesç­‰å¤šç§è¯­éŸ³è¯†åˆ«æœåŠ¡
"""
import logging
import subprocess
import json
import os
import asyncio
from typing import Optional, List, Dict, Any, Union
from pathlib import Path
from enum import Enum
import requests
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥bcut-asr
try:
    from bcut_asr import BcutASR
    from bcut_asr.orm import ResultStateEnum
    BCUT_ASR_AVAILABLE = True
except ImportError:
    BCUT_ASR_AVAILABLE = False
    logger.warning("bcut-asræœªå®‰è£…ï¼Œå°†è·³è¿‡bcut-asræ–¹æ³•")

def _auto_install_bcut_asr():
    """è‡ªåŠ¨å®‰è£…bcut-asr"""
    try:
        import subprocess
        import sys
        from pathlib import Path
        
        # è·å–å®‰è£…è„šæœ¬è·¯å¾„
        script_path = Path(__file__).parent.parent.parent / "scripts" / "install_bcut_asr.py"
        
        if not script_path.exists():
            logger.error("å®‰è£…è„šæœ¬ä¸å­˜åœ¨ï¼Œè¯·æ‰‹åŠ¨å®‰è£…bcut-asr")
            _show_manual_install_guide()
            return False
        
        logger.info("å¼€å§‹è‡ªåŠ¨å®‰è£…bcut-asr...")
        
        # è¿è¡Œå®‰è£…è„šæœ¬
        result = subprocess.run([
            sys.executable, str(script_path)
        ], capture_output=True, text=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
        
        if result.returncode == 0:
            logger.info("âœ… bcut-asrè‡ªåŠ¨å®‰è£…æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ bcut-asrè‡ªåŠ¨å®‰è£…å¤±è´¥: {result.stderr}")
            _show_manual_install_guide()
            return False
            
    except subprocess.TimeoutExpired:
        logger.error("âŒ bcut-asrå®‰è£…è¶…æ—¶")
        _show_manual_install_guide()
        return False
    except Exception as e:
        logger.error(f"âŒ bcut-asrè‡ªåŠ¨å®‰è£…å¤±è´¥: {e}")
        _show_manual_install_guide()
        return False

def _show_manual_install_guide():
    """æ˜¾ç¤ºæ‰‹åŠ¨å®‰è£…æŒ‡å¯¼"""
    logger.info("ğŸ“‹ æ‰‹åŠ¨å®‰è£…æŒ‡å¯¼:")
    logger.info("1. å®‰è£… ffmpeg:")
    logger.info("   macOS: brew install ffmpeg")
    logger.info("   Ubuntu: sudo apt install ffmpeg")
    logger.info("   Windows: winget install ffmpeg")
    logger.info("2. å®‰è£… bcut-asr:")
    logger.info("   git clone https://github.com/SocialSisterYi/bcut-asr.git")
    logger.info("   cd bcut-asr && pip install .")
    logger.info("3. è¿è¡Œæ‰‹åŠ¨å®‰è£…è„šæœ¬:")
    logger.info("   python scripts/manual_install_guide.py")

def _ensure_bcut_asr_available():
    """ç¡®ä¿bcut-asrå¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å°è¯•è‡ªåŠ¨å®‰è£…"""
    global BCUT_ASR_AVAILABLE
    
    if BCUT_ASR_AVAILABLE:
        return True
    
    logger.info("bcut-asrä¸å¯ç”¨ï¼Œå°è¯•è‡ªåŠ¨å®‰è£…...")
    
    if _auto_install_bcut_asr():
        # é‡æ–°å°è¯•å¯¼å…¥
        try:
            from bcut_asr import BcutASR
            from bcut_asr.orm import ResultStateEnum
            BCUT_ASR_AVAILABLE = True
            logger.info("âœ… bcut-asrå®‰è£…æˆåŠŸï¼Œç°åœ¨å¯ä»¥ä½¿ç”¨")
            return True
        except ImportError:
            logger.error("âŒ bcut-asrå®‰è£…åä»æ— æ³•å¯¼å…¥")
            return False
    else:
        logger.warning("âš ï¸ bcut-asrè‡ªåŠ¨å®‰è£…å¤±è´¥ï¼Œå°†ä½¿ç”¨å…¶ä»–æ–¹æ³•")
        return False


class SpeechRecognitionMethod(str, Enum):
    """è¯­éŸ³è¯†åˆ«æ–¹æ³•æšä¸¾"""
    BCUT_ASR = "bcut_asr"
    WHISPER_LOCAL = "whisper_local"
    OPENAI_API = "openai_api"
    AZURE_SPEECH = "azure_speech"
    GOOGLE_SPEECH = "google_speech"
    ALIYUN_SPEECH = "aliyun_speech"


class LanguageCode(str, Enum):
    """æ”¯æŒçš„è¯­è¨€ä»£ç """
    # ä¸­æ–‡
    CHINESE_SIMPLIFIED = "zh"
    CHINESE_TRADITIONAL = "zh-TW"
    # è‹±æ–‡
    ENGLISH = "en"
    ENGLISH_US = "en-US"
    ENGLISH_UK = "en-GB"
    # æ—¥æ–‡
    JAPANESE = "ja"
    # éŸ©æ–‡
    KOREAN = "ko"
    # æ³•æ–‡
    FRENCH = "fr"
    # å¾·æ–‡
    GERMAN = "de"
    # è¥¿ç­ç‰™æ–‡
    SPANISH = "es"
    # ä¿„æ–‡
    RUSSIAN = "ru"
    # é˜¿æ‹‰ä¼¯æ–‡
    ARABIC = "ar"
    # è‘¡è„ç‰™æ–‡
    PORTUGUESE = "pt"
    # æ„å¤§åˆ©æ–‡
    ITALIAN = "it"
    # è‡ªåŠ¨æ£€æµ‹
    AUTO = "auto"


@dataclass
class SpeechRecognitionConfig:
    """è¯­éŸ³è¯†åˆ«é…ç½®"""
    method: SpeechRecognitionMethod = SpeechRecognitionMethod.BCUT_ASR
    language: LanguageCode = LanguageCode.AUTO
    model: str = "base"  # Whisperæ¨¡å‹å¤§å°
    timeout: int = 0  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºæ— é™åˆ¶
    output_format: str = "srt"  # è¾“å‡ºæ ¼å¼
    enable_timestamps: bool = True  # æ˜¯å¦å¯ç”¨æ—¶é—´æˆ³
    enable_punctuation: bool = True  # æ˜¯å¦å¯ç”¨æ ‡ç‚¹ç¬¦å·
    enable_speaker_diarization: bool = False  # æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»
    enable_fallback: bool = True  # æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶
    fallback_method: SpeechRecognitionMethod = SpeechRecognitionMethod.WHISPER_LOCAL  # å›é€€æ–¹æ³•
    
    def __post_init__(self):
        """éªŒè¯é…ç½®å‚æ•°"""
        # éªŒè¯æ–¹æ³•
        if not isinstance(self.method, SpeechRecognitionMethod):
            try:
                self.method = SpeechRecognitionMethod(self.method)
            except ValueError:
                raise ValueError(f"ä¸æ”¯æŒçš„è¯­éŸ³è¯†åˆ«æ–¹æ³•: {self.method}")
        
        # éªŒè¯è¯­è¨€
        if not isinstance(self.language, LanguageCode):
            try:
                self.language = LanguageCode(self.language)
            except ValueError:
                raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€ä»£ç : {self.language}")
        
        # éªŒè¯æ¨¡å‹
        valid_models = ["tiny", "base", "small", "medium", "large"]
        if self.model not in valid_models:
            raise ValueError(f"ä¸æ”¯æŒçš„Whisperæ¨¡å‹: {self.model}")
        
        # éªŒè¯è¶…æ—¶æ—¶é—´
        if self.timeout < 0:
            raise ValueError("è¶…æ—¶æ—¶é—´ä¸èƒ½ä¸ºè´Ÿæ•°")
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        valid_formats = ["srt", "vtt", "txt", "json"]
        if self.output_format not in valid_formats:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {self.output_format}")


class SpeechRecognitionError(Exception):
    """è¯­éŸ³è¯†åˆ«é”™è¯¯"""
    pass


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«å™¨ï¼Œæ”¯æŒå¤šç§è¯­éŸ³è¯†åˆ«æœåŠ¡"""
    
    def __init__(self, config: Optional[SpeechRecognitionConfig] = None):
        self.config = config or SpeechRecognitionConfig()
        self.available_methods = self._check_available_methods()
    
    def _check_available_methods(self) -> Dict[SpeechRecognitionMethod, bool]:
        """æ£€æŸ¥å¯ç”¨çš„è¯­éŸ³è¯†åˆ«æ–¹æ³•"""
        methods = {}
        
        # æ£€æŸ¥bcut-asr
        methods[SpeechRecognitionMethod.BCUT_ASR] = self._check_bcut_asr_availability()
        
        # æ£€æŸ¥æœ¬åœ°Whisper
        methods[SpeechRecognitionMethod.WHISPER_LOCAL] = self._check_whisper_availability()
        
        # æ£€æŸ¥OpenAI API
        methods[SpeechRecognitionMethod.OPENAI_API] = self._check_openai_availability()
        
        # æ£€æŸ¥Azure Speech Services
        methods[SpeechRecognitionMethod.AZURE_SPEECH] = self._check_azure_speech_availability()
        
        # æ£€æŸ¥Google Speech-to-Text
        methods[SpeechRecognitionMethod.GOOGLE_SPEECH] = self._check_google_speech_availability()
        
        # æ£€æŸ¥é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«
        methods[SpeechRecognitionMethod.ALIYUN_SPEECH] = self._check_aliyun_speech_availability()
        
        return methods
    
    def _check_bcut_asr_availability(self) -> bool:
        """æ£€æŸ¥bcut-asræ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å°è¯•è‡ªåŠ¨å®‰è£…"""
        if BCUT_ASR_AVAILABLE:
            return True
        
        # å°è¯•è‡ªåŠ¨å®‰è£…
        logger.info("bcut-asrä¸å¯ç”¨ï¼Œå°è¯•è‡ªåŠ¨å®‰è£…...")
        if _ensure_bcut_asr_available():
            return True
        
        logger.warning("bcut-asrä¸å¯ç”¨ä¸”è‡ªåŠ¨å®‰è£…å¤±è´¥")
        return False
    
    def _check_whisper_availability(self) -> bool:
        """æ£€æŸ¥æœ¬åœ°Whisperæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(['whisper', '--help'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            logger.warning("æœ¬åœ°Whisperæœªå®‰è£…æˆ–ä¸å¯ç”¨")
            return False
    
    def _check_openai_availability(self) -> bool:
        """æ£€æŸ¥OpenAI APIæ˜¯å¦å¯ç”¨"""
        api_key = os.getenv("OPENAI_API_KEY")
        return api_key is not None and len(api_key.strip()) > 0
    
    def _check_azure_speech_availability(self) -> bool:
        """æ£€æŸ¥Azure Speech Servicesæ˜¯å¦å¯ç”¨"""
        api_key = os.getenv("AZURE_SPEECH_KEY")
        region = os.getenv("AZURE_SPEECH_REGION")
        return api_key is not None and region is not None
    
    def _check_google_speech_availability(self) -> bool:
        """æ£€æŸ¥Google Speech-to-Textæ˜¯å¦å¯ç”¨"""
        # æ£€æŸ¥Google Cloudå‡­è¯æ–‡ä»¶
        cred_file = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
        if cred_file and Path(cred_file).exists():
            return True
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv("GOOGLE_SPEECH_API_KEY")
        return api_key is not None
    
    def _check_aliyun_speech_availability(self) -> bool:
        """æ£€æŸ¥é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«æ˜¯å¦å¯ç”¨"""
        access_key = os.getenv("ALIYUN_ACCESS_KEY_ID")
        secret_key = os.getenv("ALIYUN_ACCESS_KEY_SECRET")
        app_key = os.getenv("ALIYUN_SPEECH_APP_KEY")
        return access_key is not None and secret_key is not None and app_key is not None
    
    def _extract_audio_from_video(self, video_path: Path, output_dir: Path) -> Path:
        """
        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æå–çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode != 0:
                raise SpeechRecognitionError("ffmpegä¸å¯ç”¨ï¼Œè¯·å®‰è£…ffmpeg")
            
            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_filename = f"{video_path.stem}_audio.wav"
            audio_path = output_dir / audio_filename
            
            # å¦‚æœéŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
            if audio_path.exists():
                logger.info(f"éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨: {audio_path}")
                return audio_path
            
            logger.info(f"æ­£åœ¨ä»è§†é¢‘æå–éŸ³é¢‘: {video_path} -> {audio_path}")
            
            # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-vn',  # ä¸å¤„ç†è§†é¢‘æµ
                '-acodec', 'pcm_s16le',  # ä½¿ç”¨PCM 16ä½ç¼–ç 
                '-ar', '16000',  # é‡‡æ ·ç‡16kHz
                '-ac', '1',  # å•å£°é“
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                str(audio_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode != 0:
                raise SpeechRecognitionError(f"éŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
            
            if not audio_path.exists():
                raise SpeechRecognitionError("éŸ³é¢‘æå–å¤±è´¥ï¼Œè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
            
            logger.info(f"éŸ³é¢‘æå–æˆåŠŸ: {audio_path}")
            return audio_path
            
        except subprocess.TimeoutExpired:
            raise SpeechRecognitionError("éŸ³é¢‘æå–è¶…æ—¶")
        except Exception as e:
            raise SpeechRecognitionError(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
    
    def generate_subtitle(self, video_path: Path, output_path: Optional[Path] = None, 
                         config: Optional[SpeechRecognitionConfig] = None) -> Path:
        """
        ç”Ÿæˆå­—å¹•æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„
            config: è¯­éŸ³è¯†åˆ«é…ç½®
            
        Returns:
            ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶è·¯å¾„
            
        Raises:
            SpeechRecognitionError: è¯­éŸ³è¯†åˆ«å¤±è´¥
        """
        if not video_path.exists():
            raise SpeechRecognitionError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        config = config or self.config
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = video_path.parent / f"{video_path.stem}.{config.output_format}"
        
        # æ ¹æ®é…ç½®çš„æ–¹æ³•é€‰æ‹©è¯†åˆ«æœåŠ¡ï¼Œæ”¯æŒå›é€€æœºåˆ¶
        try:
            if config.method == SpeechRecognitionMethod.BCUT_ASR:
                return self._generate_subtitle_bcut_asr(video_path, output_path, config)
            elif config.method == SpeechRecognitionMethod.WHISPER_LOCAL:
                return self._generate_subtitle_whisper_local(video_path, output_path, config)
            elif config.method == SpeechRecognitionMethod.OPENAI_API:
                return self._generate_subtitle_openai_api(video_path, output_path, config)
            elif config.method == SpeechRecognitionMethod.AZURE_SPEECH:
                return self._generate_subtitle_azure_speech(video_path, output_path, config)
            elif config.method == SpeechRecognitionMethod.GOOGLE_SPEECH:
                return self._generate_subtitle_google_speech(video_path, output_path, config)
            elif config.method == SpeechRecognitionMethod.ALIYUN_SPEECH:
                return self._generate_subtitle_aliyun_speech(video_path, output_path, config)
            else:
                raise SpeechRecognitionError(f"ä¸æ”¯æŒçš„è¯­éŸ³è¯†åˆ«æ–¹æ³•: {config.method}")
        except SpeechRecognitionError as e:
            # å¦‚æœå¯ç”¨äº†å›é€€æœºåˆ¶ä¸”å½“å‰æ–¹æ³•ä¸æ˜¯å›é€€æ–¹æ³•ï¼Œåˆ™å°è¯•å›é€€
            if (config.enable_fallback and 
                config.method != config.fallback_method and 
                self.available_methods.get(config.fallback_method, False)):
                
                logger.warning(f"ä¸»æ–¹æ³• {config.method} å¤±è´¥: {e}")
                logger.info(f"å°è¯•å›é€€åˆ° {config.fallback_method}")
                
                # åˆ›å»ºå›é€€é…ç½®
                fallback_config = SpeechRecognitionConfig(
                    method=config.fallback_method,
                    language=config.language,
                    model=config.model,
                    timeout=config.timeout,
                    output_format=config.output_format,
                    enable_timestamps=config.enable_timestamps,
                    enable_punctuation=config.enable_punctuation,
                    enable_speaker_diarization=config.enable_speaker_diarization,
                    enable_fallback=False  # é¿å…æ— é™å›é€€
                )
                
                return self.generate_subtitle(video_path, output_path, fallback_config)
            else:
                raise
    
    def _generate_subtitle_bcut_asr(self, video_path: Path, output_path: Path, 
                                   config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨bcut-asrç”Ÿæˆå­—å¹•"""
        # ç¡®ä¿bcut-asrå¯ç”¨
        if not _ensure_bcut_asr_available():
            raise SpeechRecognitionError(
                "bcut-asrä¸å¯ç”¨ä¸”è‡ªåŠ¨å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…:\n"
                "1. è¿è¡Œ: python scripts/install_bcut_asr.py\n"
                "2. æˆ–æ‰‹åŠ¨å®‰è£…: git clone https://github.com/SocialSisterYi/bcut-asr.git\n"
                "3. åŒæ—¶ç¡®ä¿å·²å®‰è£…ffmpeg:\n"
                "   macOS: brew install ffmpeg\n"
                "   Ubuntu: sudo apt install ffmpeg\n"
                "   Windows: winget install ffmpeg"
            )
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨bcut-asrç”Ÿæˆå­—å¹•: {video_path}")
            
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not video_path.exists():
                raise SpeechRecognitionError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶å¤§å°
            file_size = video_path.stat().st_size
            if file_size == 0:
                raise SpeechRecognitionError(f"è§†é¢‘æ–‡ä»¶ä¸ºç©º: {video_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼Œå¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶éœ€è¦å…ˆæå–éŸ³é¢‘
            audio_path = self._extract_audio_from_video(video_path, output_path.parent)
            
            # åˆ›å»ºBcutASRå®ä¾‹ï¼Œä½¿ç”¨éŸ³é¢‘æ–‡ä»¶
            asr = BcutASR(str(audio_path))
            
            # ä¸Šä¼ æ–‡ä»¶
            logger.info("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°bcut-asr...")
            asr.upload()
            
            # åˆ›å»ºä»»åŠ¡
            logger.info("æ­£åœ¨åˆ›å»ºè¯†åˆ«ä»»åŠ¡...")
            asr.create_task()
            
            # è½®è¯¢æ£€æŸ¥ç»“æœ
            logger.info("æ­£åœ¨ç­‰å¾…è¯†åˆ«ç»“æœ...")
            max_attempts = 60  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿï¼ˆæ¯5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
            attempt = 0
            
            while attempt < max_attempts:
                result = asr.result()
                
                # åˆ¤æ–­è¯†åˆ«æˆåŠŸ
                if result.state == ResultStateEnum.COMPLETE:
                    logger.info("bcut-asrè¯†åˆ«å®Œæˆ")
                    break
                elif result.state == ResultStateEnum.FAILED:
                    raise SpeechRecognitionError("bcut-asrè¯†åˆ«å¤±è´¥")
                
                # ç­‰å¾…5ç§’åé‡è¯•
                import time
                time.sleep(5)
                attempt += 1
                logger.info(f"ç­‰å¾…è¯†åˆ«ç»“æœ... ({attempt}/{max_attempts})")
            else:
                raise SpeechRecognitionError("bcut-asrè¯†åˆ«è¶…æ—¶")
            
            # è§£æå­—å¹•å†…å®¹
            subtitle = result.parse()
            
            # åˆ¤æ–­æ˜¯å¦å­˜åœ¨å­—å¹•
            if not subtitle.has_data():
                raise SpeechRecognitionError("bcut-asræœªè¯†åˆ«åˆ°æœ‰æ•ˆå­—å¹•å†…å®¹")
            
            # æ ¹æ®è¾“å‡ºæ ¼å¼ä¿å­˜å­—å¹•
            if config.output_format == "srt":
                subtitle_content = subtitle.to_srt()
            elif config.output_format == "json":
                subtitle_content = subtitle.to_json()
            elif config.output_format == "lrc":
                subtitle_content = subtitle.to_lrc()
            elif config.output_format == "txt":
                subtitle_content = subtitle.to_txt()
            else:
                # é»˜è®¤ä½¿ç”¨srtæ ¼å¼
                subtitle_content = subtitle.to_srt()
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(subtitle_content)
            
            logger.info(f"bcut-asrå­—å¹•ç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
            
        except Exception as e:
            error_msg = f"bcut-asrç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}\n"
            error_msg += "å¯èƒ½çš„åŸå› :\n"
            error_msg += "1. ç½‘ç»œè¿æ¥é—®é¢˜\n"
            error_msg += "2. æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ\n"
            error_msg += "3. æ–‡ä»¶è¿‡å¤§\n"
            error_msg += "4. bcut-asræœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def _generate_subtitle_whisper_local(self, video_path: Path, output_path: Path, 
                                       config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨æœ¬åœ°Whisperç”Ÿæˆå­—å¹•"""
        if not self.available_methods[SpeechRecognitionMethod.WHISPER_LOCAL]:
            raise SpeechRecognitionError(
                "æœ¬åœ°Whisperä¸å¯ç”¨ï¼Œè¯·å®‰è£…whisper: pip install openai-whisper\n"
                "åŒæ—¶ç¡®ä¿å·²å®‰è£…ffmpeg:\n"
                "  macOS: brew install ffmpeg\n"
                "  Ubuntu: sudo apt install ffmpeg\n"
                "  Windows: ä¸‹è½½ffmpegå¹¶æ·»åŠ åˆ°PATH"
            )
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨æœ¬åœ°Whisperç”Ÿæˆå­—å¹•: {video_path}")
            
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not video_path.exists():
                raise SpeechRecognitionError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶å¤§å°
            file_size = video_path.stat().st_size
            if file_size == 0:
                raise SpeechRecognitionError(f"è§†é¢‘æ–‡ä»¶ä¸ºç©º: {video_path}")
            
            # æ„å»ºwhisperå‘½ä»¤
            cmd = [
                'whisper',
                str(video_path),
                '--output_dir', str(output_path.parent),
                '--output_format', config.output_format,
                '--model', config.model
            ]
            
            # æ·»åŠ è¯­è¨€å‚æ•°
            if config.language != LanguageCode.AUTO:
                cmd.extend(['--language', config.language])
            
            # æ·»åŠ è¶…æ—¶å¤„ç†
            logger.info(f"æ‰§è¡ŒWhisperå‘½ä»¤: {' '.join(cmd)}")
            
            # æ ¹æ®è¶…æ—¶é…ç½®å†³å®šæ˜¯å¦è®¾ç½®è¶…æ—¶
            if config.timeout > 0:
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    text=True, 
                    timeout=config.timeout,
                    cwd=str(video_path.parent)  # è®¾ç½®å·¥ä½œç›®å½•
                )
            else:
                # æ— è¶…æ—¶é™åˆ¶
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    text=True, 
                    cwd=str(video_path.parent)  # è®¾ç½®å·¥ä½œç›®å½•
                )
            
            if result.returncode == 0:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if output_path.exists():
                    logger.info(f"æœ¬åœ°Whisperå­—å¹•ç”ŸæˆæˆåŠŸ: {output_path}")
                    return output_path
                else:
                    # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶
                    possible_outputs = list(output_path.parent.glob(f"{video_path.stem}*.{config.output_format}"))
                    if possible_outputs:
                        actual_output = possible_outputs[0]
                        logger.info(f"æ‰¾åˆ°Whisperè¾“å‡ºæ–‡ä»¶: {actual_output}")
                        return actual_output
                    else:
                        raise SpeechRecognitionError(f"Whisperæ‰§è¡ŒæˆåŠŸä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: {output_path}")
            else:
                error_msg = f"æœ¬åœ°Whisperæ‰§è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode}):\n"
                if result.stderr:
                    error_msg += f"é”™è¯¯ä¿¡æ¯: {result.stderr}\n"
                if result.stdout:
                    error_msg += f"è¾“å‡ºä¿¡æ¯: {result.stdout}"
                
                # æä¾›å…·ä½“çš„é”™è¯¯è§£å†³å»ºè®®
                if "command not found" in result.stderr:
                    error_msg += "\n\nè§£å†³æ–¹æ¡ˆ: è¯·å®‰è£…whisper: pip install openai-whisper"
                elif "ffmpeg" in result.stderr.lower():
                    error_msg += "\n\nè§£å†³æ–¹æ¡ˆ: è¯·å®‰è£…ffmpeg:\n  macOS: brew install ffmpeg\n  Ubuntu: sudo apt install ffmpeg"
                elif "timeout" in result.stderr.lower():
                    error_msg += f"\n\nè§£å†³æ–¹æ¡ˆ: è§†é¢‘å¤„ç†è¶…æ—¶ï¼Œè¯·å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (--model tiny) æˆ–å¢åŠ è¶…æ—¶æ—¶é—´"
                
                logger.error(error_msg)
                raise SpeechRecognitionError(error_msg)
                
        except subprocess.TimeoutExpired:
            error_msg = f"æœ¬åœ°Whisperæ‰§è¡Œè¶…æ—¶ï¼ˆ{config.timeout}ç§’ï¼‰\n"
            error_msg += "è§£å†³æ–¹æ¡ˆ:\n"
            error_msg += "1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹: --model tiny\n"
            error_msg += "2. å¢åŠ è¶…æ—¶æ—¶é—´\n"
            error_msg += "3. æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸå"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
        except FileNotFoundError:
            error_msg = "æ‰¾ä¸åˆ°whisperå‘½ä»¤\n"
            error_msg += "è§£å†³æ–¹æ¡ˆ:\n"
            error_msg += "1. å®‰è£…whisper: pip install openai-whisper\n"
            error_msg += "2. ç¡®ä¿whisperåœ¨PATHä¸­: which whisper\n"
            error_msg += "3. é‡æ–°å®‰è£…: pip uninstall openai-whisper && pip install openai-whisper"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
        except Exception as e:
            error_msg = f"æœ¬åœ°Whisperç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}\n"
            error_msg += "è¯·æ£€æŸ¥:\n"
            error_msg += "1. è§†é¢‘æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ\n"
            error_msg += "2. ç³»ç»Ÿæ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å­˜\n"
            error_msg += "3. æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def _generate_subtitle_openai_api(self, video_path: Path, output_path: Path, 
                                    config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨OpenAI APIç”Ÿæˆå­—å¹•"""
        if not self.available_methods[SpeechRecognitionMethod.OPENAI_API]:
            raise SpeechRecognitionError("OpenAI APIä¸å¯ç”¨ï¼Œè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨OpenAI APIç”Ÿæˆå­—å¹•: {video_path}")
            
            # è¿™é‡Œéœ€è¦å®ç°OpenAI APIè°ƒç”¨
            # ç”±äºéœ€è¦é¢å¤–çš„ä¾èµ–ï¼Œè¿™é‡Œå…ˆæŠ›å‡ºå¼‚å¸¸
            raise SpeechRecognitionError("OpenAI APIåŠŸèƒ½æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨æœ¬åœ°Whisper")
            
        except Exception as e:
            error_msg = f"OpenAI APIç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def _generate_subtitle_azure_speech(self, video_path: Path, output_path: Path, 
                                      config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨Azure Speech Servicesç”Ÿæˆå­—å¹•"""
        if not self.available_methods[SpeechRecognitionMethod.AZURE_SPEECH]:
            raise SpeechRecognitionError("Azure Speech Servicesä¸å¯ç”¨ï¼Œè¯·è®¾ç½®AZURE_SPEECH_KEYå’ŒAZURE_SPEECH_REGIONç¯å¢ƒå˜é‡")
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨Azure Speech Servicesç”Ÿæˆå­—å¹•: {video_path}")
            
            # è¿™é‡Œéœ€è¦å®ç°Azure Speech Servicesè°ƒç”¨
            raise SpeechRecognitionError("Azure Speech ServicesåŠŸèƒ½æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨æœ¬åœ°Whisper")
            
        except Exception as e:
            error_msg = f"Azure Speech Servicesç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def _generate_subtitle_google_speech(self, video_path: Path, output_path: Path, 
                                       config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨Google Speech-to-Textç”Ÿæˆå­—å¹•"""
        if not self.available_methods[SpeechRecognitionMethod.GOOGLE_SPEECH]:
            raise SpeechRecognitionError("Google Speech-to-Textä¸å¯ç”¨ï¼Œè¯·è®¾ç½®GOOGLE_APPLICATION_CREDENTIALSæˆ–GOOGLE_SPEECH_API_KEYç¯å¢ƒå˜é‡")
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨Google Speech-to-Textç”Ÿæˆå­—å¹•: {video_path}")
            
            # è¿™é‡Œéœ€è¦å®ç°Google Speech-to-Textè°ƒç”¨
            raise SpeechRecognitionError("Google Speech-to-TextåŠŸèƒ½æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨æœ¬åœ°Whisper")
            
        except Exception as e:
            error_msg = f"Google Speech-to-Textç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def _generate_subtitle_aliyun_speech(self, video_path: Path, output_path: Path, 
                                       config: SpeechRecognitionConfig) -> Path:
        """ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«ç”Ÿæˆå­—å¹•"""
        if not self.available_methods[SpeechRecognitionMethod.ALIYUN_SPEECH]:
            raise SpeechRecognitionError("é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨ï¼Œè¯·è®¾ç½®ALIYUN_ACCESS_KEY_IDã€ALIYUN_ACCESS_KEY_SECRETå’ŒALIYUN_SPEECH_APP_KEYç¯å¢ƒå˜é‡")
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«ç”Ÿæˆå­—å¹•: {video_path}")
            
            # è¿™é‡Œéœ€è¦å®ç°é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«è°ƒç”¨
            raise SpeechRecognitionError("é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«åŠŸèƒ½æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨æœ¬åœ°Whisper")
            
        except Exception as e:
            error_msg = f"é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«ç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            raise SpeechRecognitionError(error_msg)
    
    def get_available_methods(self) -> Dict[SpeechRecognitionMethod, bool]:
        """è·å–å¯ç”¨çš„è¯­éŸ³è¯†åˆ«æ–¹æ³•"""
        return self.available_methods.copy()
    
    def get_supported_languages(self) -> List[LanguageCode]:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        return list(LanguageCode)
    
    def get_whisper_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„Whisperæ¨¡å‹åˆ—è¡¨"""
        return ["tiny", "base", "small", "medium", "large"]


def generate_subtitle_for_video(video_path: Path, output_path: Optional[Path] = None, 
                               method: str = "auto", language: str = "auto", 
                               model: str = "base", enable_fallback: bool = True) -> Path:
    """
    ä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•æ–‡ä»¶çš„ä¾¿æ·å‡½æ•°
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„
        method: ç”Ÿæˆæ–¹æ³• ("auto", "bcut_asr", "whisper_local", "openai_api", "azure_speech", "google_speech", "aliyun_speech")
        language: è¯­è¨€ä»£ç 
        model: Whisperæ¨¡å‹å¤§å°ï¼ˆä»…å¯¹whisper_localæœ‰æ•ˆï¼‰
        enable_fallback: æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶
        
    Returns:
        ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶è·¯å¾„
        
    Raises:
        SpeechRecognitionError: è¯­éŸ³è¯†åˆ«å¤±è´¥
    """
    # åˆ›å»ºé…ç½®
    config = SpeechRecognitionConfig(
        method=SpeechRecognitionMethod(method) if method != "auto" else SpeechRecognitionMethod.BCUT_ASR,
        language=LanguageCode(language),
        model=model,
        enable_fallback=enable_fallback
    )
    
    recognizer = SpeechRecognizer()
    
    if method == "auto":
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
        available_methods = recognizer.get_available_methods()
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æ–¹æ³•ï¼ˆbcut-asrä¼˜å…ˆï¼Œå› ä¸ºé€Ÿåº¦æ›´å¿«ï¼‰
        priority_methods = [
            SpeechRecognitionMethod.BCUT_ASR,
            SpeechRecognitionMethod.WHISPER_LOCAL,
            SpeechRecognitionMethod.OPENAI_API,
            SpeechRecognitionMethod.AZURE_SPEECH,
            SpeechRecognitionMethod.GOOGLE_SPEECH,
            SpeechRecognitionMethod.ALIYUN_SPEECH
        ]
        
        for priority_method in priority_methods:
            if available_methods.get(priority_method, False):
                config.method = priority_method
                break
        else:
            raise SpeechRecognitionError("æ²¡æœ‰å¯ç”¨çš„è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œè¯·å®‰è£…whisperæˆ–é…ç½®APIå¯†é’¥")
    
    return recognizer.generate_subtitle(video_path, output_path, config)


def get_available_speech_recognition_methods() -> Dict[str, bool]:
    """
    è·å–å¯ç”¨çš„è¯­éŸ³è¯†åˆ«æ–¹æ³•
    
    Returns:
        å¯ç”¨æ–¹æ³•å­—å…¸
    """
    recognizer = SpeechRecognizer()
    available_methods = recognizer.get_available_methods()
    
    return {
        method.value: available 
        for method, available in available_methods.items()
    }


def get_supported_languages() -> List[str]:
    """
    è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
    
    Returns:
        æ”¯æŒçš„è¯­è¨€ä»£ç åˆ—è¡¨
    """
    return [lang.value for lang in LanguageCode]


def get_whisper_models() -> List[str]:
    """
    è·å–å¯ç”¨çš„Whisperæ¨¡å‹åˆ—è¡¨
    
    Returns:
        Whisperæ¨¡å‹åˆ—è¡¨
    """
    return ["tiny", "base", "small", "medium", "large"]
