#!/usr/bin/env python3
"""
æŒ‰ç…§åŸæœ‰æ¶æ„æ‰§è¡ŒçœŸå®æµæ°´çº¿çš„è„šæœ¬
ä½¿ç”¨PipelineAdapterå’ŒåŸæœ‰çš„æµæ°´çº¿æ­¥éª¤
"""

import sys
import os
import json
import asyncio
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ..core.database import SessionLocal
from ..models.project import Project, ProjectStatus
from ..models.task import Task, TaskStatus
from ..services.pipeline_adapter import create_pipeline_adapter_sync
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def execute_real_pipeline(project_id: str):
    """æŒ‰ç…§åŸæœ‰æ¶æ„æ‰§è¡ŒçœŸå®æµæ°´çº¿"""
    
    logger.info(f"å¼€å§‹æ‰§è¡Œé¡¹ç›® {project_id} çš„çœŸå®æµæ°´çº¿")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ä¼šè¯
        db = SessionLocal()
        
        try:
            # éªŒè¯é¡¹ç›®æ˜¯å¦å­˜åœ¨
            project = db.query(Project).filter(Project.id == project_id).first()
            if not project:
                raise ValueError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            
            logger.info(f"éªŒè¯é¡¹ç›®å­˜åœ¨: {project.name}")
            
            # åˆ›å»ºä»»åŠ¡è®°å½•
            task = Task(
                name=f"çœŸå®æµæ°´çº¿å¤„ç†",
                description=f"ä½¿ç”¨åŸæœ‰æ¶æ„å¤„ç†é¡¹ç›® {project_id}",
                task_type="VIDEO_PROCESSING",
                project_id=project_id,
                status=TaskStatus.RUNNING,
                progress=0,
                current_step="åˆå§‹åŒ–",
                total_steps=6
            )
            db.add(task)
            db.commit()
            db.refresh(task)
            
            logger.info(f"ä»»åŠ¡è®°å½•å·²åˆ›å»º: {task.id}")
            
            # å‡†å¤‡æ–‡ä»¶è·¯å¾„
            data_root = project_root / "data" / "projects" / project_id
            input_video_path = data_root / "raw" / "input.mp4"
            input_srt_path = data_root / "raw" / "input.srt"
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not input_video_path.exists():
                raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_video_path}")
            if not input_srt_path.exists():
                raise FileNotFoundError(f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {input_srt_path}")
            
            logger.info(f"æ–‡ä»¶è·¯å¾„éªŒè¯æˆåŠŸ:")
            logger.info(f"  è§†é¢‘: {input_video_path}")
            logger.info(f"  å­—å¹•: {input_srt_path}")
            
            # åˆ›å»ºPipelineé€‚é…å™¨
            pipeline_adapter = create_pipeline_adapter_sync(db, str(task.id), project_id)
            
            # éªŒè¯æµæ°´çº¿å‰ç½®æ¡ä»¶
            logger.info("éªŒè¯æµæ°´çº¿å‰ç½®æ¡ä»¶...")
            errors = pipeline_adapter.validate_pipeline_prerequisites()
            if errors:
                error_msg = "; ".join(errors)
                logger.error(f"æµæ°´çº¿å‰ç½®æ¡ä»¶éªŒè¯å¤±è´¥: {error_msg}")
                raise ValueError(f"æµæ°´çº¿å‰ç½®æ¡ä»¶éªŒè¯å¤±è´¥: {error_msg}")
            
            logger.info("æµæ°´çº¿å‰ç½®æ¡ä»¶éªŒè¯é€šè¿‡")
            
            # æ‰§è¡Œå®Œæ•´çš„æµæ°´çº¿å¤„ç†
            logger.info("å¼€å§‹æ‰§è¡Œå®Œæ•´æµæ°´çº¿...")
            result = pipeline_adapter.process_project_sync(
                project_id=project_id,
                input_video_path=str(input_video_path),
                input_srt_path=str(input_srt_path)
            )
            
            # æ£€æŸ¥å¤„ç†ç»“æœ
            if result.get('status') == 'failed':
                error_msg = result.get('message', 'å¤„ç†å¤±è´¥')
                logger.error(f"æµæ°´çº¿å¤„ç†å¤±è´¥: {error_msg}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                task.status = TaskStatus.FAILED
                task.error_message = error_msg
                db.commit()
                
                return {
                    "success": False,
                    "error": error_msg,
                    "result": result
                }
            else:
                # å¤„ç†æˆåŠŸ
                logger.info("ğŸ‰ æµæ°´çº¿å¤„ç†æˆåŠŸï¼")
                logger.info(f"å¤„ç†ç»“æœ: {result}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                task.status = TaskStatus.COMPLETED
                task.progress = 100
                task.current_step = "å¤„ç†å®Œæˆ"
                db.commit()
                
                return {
                    "success": True,
                    "result": result,
                    "message": "æµæ°´çº¿å¤„ç†å®Œæˆ"
                }
                
        finally:
            db.close()
            
    except Exception as e:
        error_msg = f"æ‰§è¡Œæµæ°´çº¿å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        
        # å°è¯•æ›´æ–°ä»»åŠ¡çŠ¶æ€
        try:
            db = SessionLocal()
            task = db.query(Task).filter(Task.project_id == project_id).order_by(Task.created_at.desc()).first()
            if task:
                task.status = TaskStatus.FAILED
                task.error_message = error_msg
                db.commit()
            db.close()
        except Exception as db_error:
            logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {db_error}")
        
        return {
            "success": False,
            "error": error_msg
        }

async def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python execute_real_pipeline.py <project_id>")
        sys.exit(1)
    
    project_id = sys.argv[1]
    
    result = await execute_real_pipeline(project_id)
    
    if result["success"]:
        print(f"âœ… æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š ç»“æœ: {result['result']}")
    else:
        print(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {result['error']}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
